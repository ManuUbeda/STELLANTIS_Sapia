# -*- coding: utf-8 -*-
"""NoteBook_final_Stellantis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wtbnt7CxagimcNLDxtD2V6c9ZpwG_YQ-

# Importation des packages
"""

#Import des packages
import pandas as pd #Pour DataFrames
import numpy as np # pour calculs
import matplotlib.pyplot as plt #pour graphiques
import seaborn as sns # pour esthétique des graphiques

"""# Importation des données et créations des DataFrames"""

df=pd.read_excel('/content/SX_EMB_POWERBI.xlsx', sheet_name = None, header =1)

df_convoi = df['2_CONVOI']

df_arrets = df['3_arret']

df_gammes = df['Gamme']

"""# Exploration des DataFrames

**Exploration de df_convoi**
"""

df_convoi.info()

df_convoi.head()

df_convoi.isna().sum() #On compte le nombre de NaN, on remarque qu'il faudra dropper

df_convoi.duplicated().sum() #somme des doublons

"""**Exploration de df_arrets**"""

df_arrets.info()

df_arrets.head()

df_arrets.isna().mean()

df_arrets.duplicated().sum()

"""**Exploration de df_gammes**"""

df_gammes.info()

df_gammes.head()

df_gammes.isna().sum()

df_gammes.duplicated().sum()

"""# Nettoyage des données

#DF_ARRETS
"""

df_arrets.drop(columns = 'Unnamed: 0', inplace = True) # on droppe l'ancien index

df_test = df_arrets.copy() # on fait une copie pour travailler dessus

"""**Gestion des NaN**"""

df_test['3_Rubrique'] = df_test['3_Rubrique'].replace(np.NaN, 'Divers') # on remplace les nan par Divers dans Rubrique

# df_test['3_Commentaire'] = df_test['3_Commentaire'].replace(np.NaN, 'Sans commentaire')    ON LAISSE les NaNs

df_test

df_test.isna().sum() # on voit qu'il reste des NaNs dans Sous_famille

df_test['3_Sous_famille'] = df_test['3_Sous_famille'].replace(np.NaN, 'Non renseigné') # On s'occupe des NaN dans Sous_famille
df_test['3_Sous_famille'].isna().sum()

# df_test[df_test['3_Rubrique'] == 'AUTRES'].sample(10) à voir à quoi elle sert?

df_arrets = df_test.copy() # On update df_arrets avec ce qu'on a fait

# Création d'une colonne Debut_Date pour la date de début et d'une colonne Debut_Time pour l'heure de début
df_arrets['Debut_Date'] = [d.date() for d in df_arrets['3_Debut']]
# df_arrets['Debut_Time'] = [d.time() for d in df_arrets['3_Debut']]

df_arrets['Debut_Date'] = pd.to_datetime(df_arrets['Debut_Date']) # Conversion de Debut_Date en format datetime

df_arrets.info()

#Création d'une clé étrangère
df_arrets["FK_arrets"]=df_arrets["3_LocalisationSuiviArrets"]+"_"+ df_arrets['3_num_convoi']

"""# DF_CONVOI"""

df_convoi.drop(columns = 'Unnamed: 0', inplace = True) #on drop ancien index

df_convoi=df_convoi[(df_convoi["2_Cadence Instantanee"]>=0) & (df_convoi["2_Cadence Instantanee"]<500)] # on filtre la cadence instantanée entre 0 & 500 pour éliminer les valeurs abhérantes

df_convoi['2_DureeConvoi_HHMM'] = (df_convoi['2_Fin'] - df_convoi['2_Debut']).dt.total_seconds() / 3600 # création d'une colonne durée convoi en heures & minutes
df_convoi['2_DureeConvoi_HHMM'] = df_convoi['2_DureeConvoi_HHMM'].round(1)

df_convoi.info() # on vérifie les types

# df_convoi.drop(columns = '2_DureeConvoi', inplace = True) à voir si on le fait plus tard, quand on a plus besoin des secondes

df_convoi.rename(columns= {'2_DureeConvoi_HHMM': '2_DureeConvoi(h)'}, inplace = True) # on renomme la nouvelle colonne

#Création d'une clé primaire
df_convoi["PK_convoi"]=df_convoi["2_Localisation"]+"_"+ df_convoi["2_Num_Convoi"]

"""Vérification des CHU_convoi et CHR_convoi égale à 0 car il faudra les analyser ces colonnes plus tard"""

var=df_convoi[df_convoi['2_Chu Convoi']==0]

nombre_lignes_filtrees=len(var)

nombre_lignes_filtrees

var2=df_convoi[df_convoi['2_Chr Convoi']==0]

nombre_lignes_filtrees2=len(var2)

nombre_lignes_filtrees2

"""Etude des outliers pour les variables numériques Chu_convoi et Chr_convoi"""

df_convoi.loc[df_convoi["2_Chu Convoi"]>3000,"2_Chu Convoi"]=100

df_convoi

sns.boxplot(data=df_convoi,x='2_Chu Convoi',y="2_Debut", color='skyblue', fliersize=2, linewidth=8)

df_convoi.loc[df_convoi["2_Chr Convoi"]>3000,"2_Chr Convoi"]=100

df_convoi

"""#DF_GAMMES"""

df_gammes.drop(columns = 'Unnamed: 0', inplace = True) # drop ancien index

df_gammes.info() #vérification des types et NaNs, on décide de laisser le seul NaN

"""# Repérage des clés uniques pour les utiliser ensuite dans Power BI"""

df_convoi.info() #On repère num_convoi qui pourrait être une clé primaire

df_convoi['2_Num_Convoi'].nunique() # Confirmation si Num_convoi respecte l'unicité

df_gammes.info() #Num_Gamme _Ideo semble être clé primaire

df_gammes['7_Num_Gamme _Ideo'].nunique() # vérification

df_arrets.info()

df_arrets = df_arrets.sort_values(by = 'Debut_Date')

df_gammes = df_gammes.sort_values(by='7_Num_Gamme _Ideo')

df_convoi = df_convoi.sort_values(by='2_Debut')

df_convoi

df_arrets

"""# Exports excel de df_convoi & df_gammes pour Power BI"""

from google.colab import files
with pd.ExcelWriter('/content/convois.xlsx') as excel_writer:
    df_convoi.to_excel(excel_writer, sheet_name='2_CONVOIS', index=False)
files.download('/content/convois.xlsx')

from google.colab import files
with pd.ExcelWriter('/content/gamme.xlsx') as excel_writer:
    df_gammes.to_excel(excel_writer, sheet_name='Gamme', index=False)
files.download('/content/gamme.xlsx')

"""# Gestion des durées des arrêts qui chevauchent plusieurs jours dans df_arrets"""

from datetime import date # Import du package nécessaire

def split_arret(row):
    temp = []
    start_time = row['3_Debut']
    duration = row['3_DureeArretBrutNonForma']

    midnight = pd.Timestamp(year=start_time.year, month=start_time.month, day=start_time.day, hour=23, minute=59, second=59)

    if start_time + pd.Timedelta(seconds=duration) > midnight:
        duration_before_midnight = (midnight - start_time).total_seconds()
        duration_after_midnight = duration - duration_before_midnight

        donnee = {
            '3_Commentaire': row['3_Commentaire'],
            '3_Debut': start_time,
            '3_Famille': row['3_Famille'],
            '3_LocalisationSuiviArrets': row['3_LocalisationSuiviArrets'],
            '3_mnemonique': row['3_mnemonique'],
            '3_num_convoi': row['3_num_convoi'],
            '3_Rubrique': row['3_Rubrique'],
            '3_Sous_famille': row['3_Sous_famille'],
            '3_DureeArretBrutNonForma': duration_before_midnight
        }
        temp.append(donnee)

        new_start_time = midnight + pd.Timedelta(seconds=1)
        time_remaining = duration - duration_before_midnight

        while time_remaining > 0:
            if time_remaining > 86400:
                donnee = {
                    '3_Commentaire': row['3_Commentaire'],
                    '3_Debut': new_start_time,
                    '3_Famille': row['3_Famille'],
                    '3_LocalisationSuiviArrets': row['3_LocalisationSuiviArrets'],
                    '3_mnemonique': row['3_mnemonique'],
                    '3_num_convoi': row['3_num_convoi'],
                    '3_Rubrique': row['3_Rubrique'],
                    '3_Sous_famille': row['3_Sous_famille'],
                    '3_DureeArretBrutNonForma': 86400
                }
                temp.append(donnee)
                time_remaining -= 86400
                new_start_time += pd.Timedelta(hours=24)
            else:
                donnee = {
                    '3_Commentaire': row['3_Commentaire'],
                    '3_Debut': new_start_time,
                    '3_Famille': row['3_Famille'],
                    '3_LocalisationSuiviArrets': row['3_LocalisationSuiviArrets'],
                    '3_mnemonique': row['3_mnemonique'],
                    '3_num_convoi': row['3_num_convoi'],
                    '3_Rubrique': row['3_Rubrique'],
                    '3_Sous_famille': row['3_Sous_famille'],
                    '3_DureeArretBrutNonForma': time_remaining
                }
                temp.append(donnee)
                time_remaining = 0

    # Return the DataFrame after processing all segments
    return pd.DataFrame(temp) if temp else pd.DataFrame([row])  # if temp is empty, return the original row

df_arrets_final = pd.concat(df_arrets.apply(split_arret, axis=1).to_list(), ignore_index=True)

display(df_arrets_final)

#df_arrets_final.to_excel('df.xlsx', index=False)

df_arrets_final = df_arrets_final.sort_values(by='3_Debut')   # trie sur la colonne 3_Début par ordre croissant

df_arrets_final.info() # on vérifie le dataframe après la boucle (types, NaNs, nombre de lignes)

from google.colab import files
with pd.ExcelWriter('/content/arrets.xlsx') as excel_writer:
    df_arrets_final.to_excel(excel_writer, sheet_name='3_arrets', index=False)
files.download('/content/arrets.xlsx')

"""# Création groupes Planifie et Non-Planifie dans df_arrets"""

df_arrets_final['arret_planifie'] = np.nan #création de la colonne vide qui accueillera nouvelles valeurs

df_arrets_final['3_Famille'].unique() # affichages des valeurs de la colonne pour vérifier les noms avant la boucle

# Boucle pour assigner si l'arrêt est planifié ou non selon sa famille
for x in range(len(df_arrets_final)):
  if df_arrets_final['3_Famille'].loc[x] == 'HORS PRODUCTION':
    df_arrets_final['arret_planifie'].loc[x] = 'yes'
  elif df_arrets_final['3_Famille'].loc[x] == 'INTEGRATION NOUVELLE GAMME':
    df_arrets_final['arret_planifie'].loc[x] = 'yes'
  elif df_arrets_final['3_Famille'].loc[x] == 'MAINTENANCE PROGRAMMEE':
    df_arrets_final['arret_planifie'].loc[x] = 'yes'
  elif df_arrets_final['3_Famille'].loc[x] == 'ORGANISATION':
    df_arrets_final['arret_planifie'].loc[x] = 'yes'
  else:
    df_arrets_final['arret_planifie'].loc[x] = 'no'

df_arrets_final.head() # vérification des résulats de la boucle

df_arrets_final['arret_planifie'].value_counts() # vérification que toutes ont bien une assignation

"""# Calculs pour le Temps Utile (TU), le Temps Effectif pour Produire (TEP) et le Rendement Opérationnel (RO)"""

#df_arrets_final["3_Debut"] = pd.to_datetime(df_arrets_final["3_Debut"])
df_arrets_final['Debut_Date'] = pd.to_datetime(df_arrets_final["Debut_Date"]) #création colonne début_date pour grouper par jour
df_arrets_final.info()

#Calcul temps d'arrêt total
DureeArretTotale = df_arrets_final['3_DureeArretBrutNonForma'].groupby([df_arrets_final['Debut_Date'], df_arrets_final['3_LocalisationSuiviArrets']]).sum().reset_index()
DureeArretTotale.rename(columns={'Debut_Date' : 'Date', '3_LocalisationSuiviArrets' : 'Ligne', '3_DureeArretBrutNonForma': 'DureeArretTotal'}, inplace=True)
DureeArretTotale

# Calcul du temps d'arrêt non planifié
df_nonplan = df_arrets_final[df_arrets_final['arret_planifie'] == 'no']
DureeNonPlan = df_nonplan['3_DureeArretBrutNonForma'].groupby([df_nonplan['Debut_Date'], df_nonplan['3_LocalisationSuiviArrets']]).sum().reset_index()
DureeNonPlan.rename(columns={'3_DureeArretBrutNonForma': 'DureeNonPlan'}, inplace=True)
DureeNonPlan

# Calcul du temps d'arrêt planifié
df_plan = df_arrets_final[df_arrets_final['arret_planifie'] == 'yes']
DureePlan = df_plan['3_DureeArretBrutNonForma'].groupby([df_plan['Debut_Date'], df_plan['3_LocalisationSuiviArrets']]).sum().reset_index()
DureePlan.rename(columns={'3_DureeArretBrutNonForma': 'DureePlan'}, inplace=True)
DureePlan

"""On checke le nombre de lignes & colonnes pour choisir entre une concaténation et une jointure"""

DureeArretTotale.shape

DureeNonPlan.shape

DureePlan.shape

"""On choisit la jointure car ils ont un nombre de lignes différents"""

# on choisit outer pour conserver toutes les lignes des dataframes
df_duree = pd.merge(DureeArretTotale, DureeNonPlan, left_on = ['Date', 'Ligne'], right_on = ['Debut_Date', '3_LocalisationSuiviArrets'], how = 'outer')
df_duree = pd.merge(df_duree, DureePlan, left_on = ['Date', 'Ligne'], right_on = ['Debut_Date', '3_LocalisationSuiviArrets'], how = 'outer')
df_duree

df_duree.drop(columns = ['3_LocalisationSuiviArrets_x', '3_LocalisationSuiviArrets_y', 'Debut_Date_y', 'Debut_Date_x'], inplace = True) # On droppe les colonnes dupliquées par le outer
df_duree

df_duree.shape #vérification nombre de lignes & colonnes

"""Calculs du TU, du TEP et du RO maintenant que nous avons le dataframe nécessaire"""

journee = 86400 #86400 est le nombre de secondes en une journée

# Calcul du TEP qui est la soustraction de 24h et des arrêts non-planifiés
df_duree['TEP'] = np.nan
for x in range(len(df_duree['DureeNonPlan'])):
  TEP = 86400 - df_duree['DureeNonPlan'].loc[x]
  df_duree['TEP'].loc[x] = TEP
df_duree

# Calcul du TU qui est la soustraction de 24h - le total des arrêts
df_duree['TU'] = np.nan
for x in range(len(df_duree['DureeArretTotal'])):
  TU = 86400 - df_duree['DureeArretTotal'].loc[x]
  df_duree['TU'].loc[x] = TU
df_duree

# Calcul du RO qui est la division du TU par TEP
df_duree['RO'] = df_duree['TU']/df_duree['TEP']
df_duree

from google.colab import files
with pd.ExcelWriter('/content/duree.xlsx') as excel_writer:
    df_duree.to_excel(excel_writer, sheet_name='duree', index=False)
files.download('/content/duree.xlsx')

"""# Traitement de la colonne Commentaires"""

# Définition de com
com = pd.read_excel('/content/df-2.xlsx')

# boucle pour retirer les nombres et mots de 2 caractères ou moins
 for x in range(len(com['commentaire_clean'])):
  for z in com['commentaire_clean'].loc[x]:
    if z.isspace():
      com['commentaire_clean'].loc[x] = com['commentaire_clean'].loc[x].replace(z,"")
    else:
      continue
    if z.isnumeric():
      com['commentaire_clean'].loc[x] = com['commentaire_clean'].loc[x].replace(z,"")
    else:
      continue
for x in range(len(com['commentaire_clean'])):
  com['commentaire_clean'].loc[x] = com['commentaire_clean'].loc[x].replace("[","")
  com['commentaire_clean'].loc[x] = com['commentaire_clean'].loc[x].replace("]","")
  com['commentaire_clean'].loc[x] = com['commentaire_clean'].loc[x].replace("'","")
  com['commentaire_clean'].loc[x] = com['commentaire_clean'].loc[x].replace("'","")
  com['commentaire_clean'].loc[x] = com['commentaire_clean'].loc[x].split(',')
for x in range(len(com['commentaire_clean'])):
  for y in reversed(com['commentaire_clean'].loc[x]):
    if len(y) < 3:
      com['commentaire_clean'].loc[x].remove(y)
    else:
      continue

with pd.ExcelWriter('/content/com-clean.xlsx') as excel_writer:
    df_duree.to_excel(excel_writer, sheet_name='com-clean', index=False)
files.download('/content/com-clean.xlsx')